{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-michael",
   "metadata": {},
   "source": [
    "# Cài đặt thuật toán K-means phân tán với PySpark\n",
    "\n",
    "- [Spark Machine Learning Library](#mllib)\n",
    "- [Thuật toán K-means với PySpark](#spark_kmeans)\n",
    "- [So sánh kết quả với thư viện Scikit-learn](#comparison)\n",
    "\n",
    "## Spark Machine Learning Library <a name=\"mllib\"/>\n",
    "\n",
    "Spark cung cấp [thư viện MLLib (Machine Learning Library)](https://spark.apache.org/docs/3.1.1/ml-guide.html) cho phép triển khai các dự án machine learning phân tán. Các tính năng của MLLib bao gồm:\n",
    "- Một số thuật toán ML tiêu biểu: phân lớp (classification), hồi qui (regression), phân cụm (clustering), collaborative filtering.\n",
    "- Xử lý đặc trưng (featurization): trích xuất (feature extraction), biến đối (transformation), giảm chiều (dimensionality reduction), chọn lọc (feature selection).\n",
    "\n",
    "- Pipelines: các công cụ xây dựng, tinh chỉnh và đánh giá mô hình ML.\n",
    "- Các tiện ích: xử lý dữ liệu, lưu/nạp mô hình, v.v.\n",
    "\n",
    "Bên cạnh thư viện MLLib (RDD-based API), hiện nay Spark cung cấp thư viện ML mới (DataFrame-based API) với nhiều tính năng dễ sử dụng hơn MLLib. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-biology",
   "metadata": {},
   "source": [
    "## Thuật toán K-means với PySpark <a name=\"spark_kmeans\"/>\n",
    "### Khai báo các thư viện "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optional-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-zambia",
   "metadata": {},
   "source": [
    "### Khởi tạo Spark Session\n",
    "\n",
    "Spark phiên bản 2.0 trở đi cung cấp lớp SparkSession để khởi tạo các chức năng của Spark. Sau khi tạo Spark Session, người dùng có thể lập trình với RDD, DataFrame và Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/08 16:44:49 WARN Utils: Your hostname, DESKTOP-HHU5MDD resolves to a loopback address: 127.0.1.1; using 192.168.1.77 instead (on interface wifi0)\n",
      "22/05/08 16:44:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/08 16:44:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create new Spark session\n",
    "spark = SparkSession.builder.appName(\"Distributed KMeans Example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-intelligence",
   "metadata": {},
   "source": [
    "### Tạo dữ liệu dạng DataFrame\n",
    "\n",
    "Với Spark Context, người dùng phải tạo mới RDD sau đó lập trình xử lý trên RDD. Spark Session cung cấp các API xử lý với các loại dữ liệu khác, gồm cả DataFrame.\n",
    "\n",
    "Để nạp dữ liệu iris vào Spark cluster, có thể thực hiện như sau: trước hết đọc dữ liệu đưa vào DataFrame dùng thư viện pandas, sau sử dụng phương thức spark.createDataFrame() để nạp dữ liệu vào Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "different-theory",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m iris_data \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mcreateDataFrame(pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/data\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=1'>2</a>\u001b[0m                                                 header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39msepal-length\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=2'>3</a>\u001b[0m                                                                     \u001b[39m'\u001b[39;49m\u001b[39msepal-width\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mpetal-length\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m                                                                     \u001b[39m'\u001b[39;49m\u001b[39mpetal-width\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFirst 10 rows:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu18wsl_bigdata/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/src/distributed-kmeans.ipynb#ch0000006vscode-remote?line=5'>6</a>\u001b[0m iris_data\u001b[39m.\u001b[39mshow(\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/hdoop/miniconda3/lib/python3.9/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/data'"
     ]
    }
   ],
   "source": [
    "iris_data = spark.createDataFrame(pd.read_csv('/mnt/d/Code/Big-Data/Lab5_DistributedMachineLearning/data/iris.data', \n",
    "                                                header=None, names=['sepal-length',\n",
    "                                                                    'sepal-width', 'petal-length', \n",
    "                                                                    'petal-width','label']))\n",
    "print(\"First 10 rows:\")\n",
    "iris_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-insertion",
   "metadata": {},
   "source": [
    "### Tạo vector đặc trưng từ DataFrame\n",
    "\n",
    "Để tạo vector đặc trưng (feature vector) cho từng dòng dữ liệu, dùng lớp VectorAssembler để ghép giá trị ở các cột trong DataFrame thành một cột mới chứa vector đặc trưng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accomplished-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|sepal-length|sepal-width|petal-length|petal-width|      label|         features|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "+------------+-----------+------------+-----------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\"], \n",
    "                            outputCol=\"features\") \n",
    "irisFeatures = assembler.transform(iris_data) \n",
    "irisFeatures.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-poverty",
   "metadata": {},
   "source": [
    "Lúc này dữ liệu đã sẵn sàng để đưa vào huấn luyện mô hình ML (ở đây là K-means).\n",
    "Gỉa sử chọn số cụm là 3, tiến hành huấn luyện mô hình K-means với PySpark bằng các lệnh sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-evidence",
   "metadata": {},
   "source": [
    "### Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amino-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình K-means với K=3 trên toàn bộ tập dữ liệu.\n",
    "# Trong thực tế, để đánh giá một mô hình ML, tập dữ liệu thường được chia làm 3 phần:\n",
    "# - train set dùng để huấn luyện,\n",
    "# - validation set dùng để đánh giá, tinh chỉnh mô hình trong quá trình huấn luyện,\n",
    "# - test set để kiểm tra hiệu năng của mô hình trên dữ liệu hoàn toàn mới.\n",
    "kmeans = KMeans().setK(3).setSeed(0)\n",
    "model = kmeans.fit(irisFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-baltimore",
   "metadata": {},
   "source": [
    "### In kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "integrated-embassy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers learned by Spark ML: \n",
      "[5.9  2.75 4.39 1.43]\n",
      "[5.01 3.42 1.46 0.24]\n",
      "[6.85 3.07 5.74 2.07]\n"
     ]
    }
   ],
   "source": [
    "# In ra tâm điểm của các cụm\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Centers learned by Spark ML: \")\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-uzbekistan",
   "metadata": {},
   "source": [
    "### So sánh với kết quả chạy K-means bằng thư viện Scikit-learn <a name=\"comparison\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indonesian-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "answering-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers learned by scikit-learn:\n",
      "[[5.9  2.75 4.39 1.43]\n",
      " [5.01 3.43 1.46 0.25]\n",
      " [6.85 3.07 5.74 2.07]]\n"
     ]
    }
   ],
   "source": [
    "# Nạp dữ liệu\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "\n",
    "print('Centers learned by scikit-learn:')\n",
    "print(kmeans.cluster_centers_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c156cbd56f2befb501b04e4bcafbb3ceb498087e79117ebbae5589b514d9d978"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('miniconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
